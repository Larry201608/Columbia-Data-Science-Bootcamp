{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross validation and model selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "% matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_boston, load_digits\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.linear_model import LogisticRegression, Ridge\n",
    "from sklearn.metrics import average_precision_score, precision_recall_curve\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV, train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Threefold split and parameter search\n",
    "The simplest way to adjust parameters is to split the data into three parts: a training, a validation and a test set.\n",
    "For each parameter setting, we fit a model on the training set, and evaluate it on the evaluation set.\n",
    "We select the \"best\" parameter setting (or model) based on the validation set. We then rebuild a model using training and\n",
    "validation data with this parameter setting, and evaluate it on the test set. The test set performance serves as an estimate of the generalization performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1\n",
    "Load the boston housing data. Split the data into three parts, for example by calling ``train_test_split`` twice.\n",
    "As yesterday, scale the data and create polynomial features.\n",
    "Search the best setting for the regularization parameter alpha using the strategy described above.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston = load_boston()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[    0.001     0.01      0.1       1.       10.      100.     1000.   ]\n"
     ]
    }
   ],
   "source": [
    "alphas = np.logspace(-3, 3, 7)\n",
    "np.set_printoptions(suppress=True)\n",
    "print(alphas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing parameter search...\n",
      "       alpha        score\n",
      "    0.001000     0.698127\n",
      "    0.010000     0.698149\n",
      "    0.100000     0.698359\n",
      "    1.000000     0.700425\n",
      "   10.000000     0.717783\n",
      "  100.000000     0.759543\n",
      " 1000.000000     0.568988\n",
      "maximum score =     0.759543\n",
      "chosen alpha  =   100.000000\n",
      "Performing fit on entire training set...\n",
      "Peforming test...\n",
      "score =     0.583461\n"
     ]
    }
   ],
   "source": [
    "X_trainval, X_test, y_trainval, y_test = train_test_split(boston.data, boston.target, random_state=0)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_trainval, y_trainval, random_state=0)\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_val = scaler.transform(X_val)\n",
    "X_trainval = scaler.transform(X_trainval)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "print(\"Performing parameter search...\")\n",
    "scores = []\n",
    "print(\"{0:>12s} {1:>12s}\".format(\"alpha\",\"score\"))\n",
    "for a in alphas:\n",
    "    ridge = Ridge(a)\n",
    "    ridge.fit(X_train, y_train)\n",
    "    score = ridge.score(X_val, y_val)\n",
    "    scores.append(score)\n",
    "    print(\"{0:12.6f} {1:12.6f}\".format(a,score))\n",
    "    \n",
    "print(\"maximum score = {:12.6f}\".format(scores[np.argmax(scores)]))\n",
    "myalpha = alphas[np.argmax(scores)]\n",
    "print(\"chosen alpha  = {:12.6f}\".format(myalpha))\n",
    "\n",
    "print(\"Performing fit on entire training set...\")\n",
    "ridge = Ridge(myalpha)\n",
    "ridge.fit(X_trainval, y_trainval)\n",
    "print(\"Peforming test...\")\n",
    "score = ridge.score(X_test, y_test)\n",
    "print(\"score = {:12.6f}\".format(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross validation\n",
    "To get a better understanding of cross-validation, we'll implement it from scratch.\n",
    "Our goal is to estimate the performance of a single model, let's say ``Ridge(alpha=1)`` on the original Boston housing dataset.\n",
    "\n",
    "### Task 2\n",
    "Complete the code below to fit a model for each of the folds of 5-fold cross-validation and compute the hold-out $R^2$ using the ``score method``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hold out the following range: 0-101\n",
      "[-- -- -- -- -- -- -- -- -- -- -- -- --]\n",
      "[0.13262 0.0 8.56 0.0 0.52 5.851 96.7 2.1069 5.0 384.0 20.9 394.05 16.47]\n",
      "0.742522041858\n",
      "[-0.40349384 -0.48832004 -0.37538041 -0.27288841 -0.29910567 -0.6179684\n",
      "  1.000203   -0.80320985 -0.52493098 -0.14549091  1.13299322  0.41034991\n",
      "  0.53341842]\n",
      "[-0.40349384 -0.48832004 -0.37538041 -0.27288841 -0.29910567 -0.6179684\n",
      "  1.000203   -0.80320985 -0.52493098 -0.14549091  1.13299322  0.41034991\n",
      "  0.53341842]\n",
      "score =     0.742522\n",
      "Hold out the following range: 101-202\n",
      "[0.13262 0.0 8.56 0.0 0.52 5.851 96.7 2.1069 5.0 384.0 20.9 394.05 16.47]\n",
      "[-- -- -- -- -- -- -- -- -- -- -- -- --]\n",
      "0.742522041858\n",
      "[-0.40349384 -0.48832004 -0.37538041 -0.27288841 -0.29910567 -0.6179684\n",
      "  1.000203   -0.80320985 -0.52493098 -0.14549091  1.13299322  0.41034991\n",
      "  0.53341842]\n",
      "[-0.40349384 -0.48832004 -0.37538041 -0.27288841 -0.29910567 -0.6179684\n",
      "  1.000203   -0.80320985 -0.52493098 -0.14549091  1.13299322  0.41034991\n",
      "  0.53341842]\n",
      "score =     0.742522\n",
      "Hold out the following range: 202-303\n",
      "[-- -- -- -- -- -- -- -- -- -- -- -- --]\n",
      "[0.13262 0.0 8.56 0.0 0.52 5.851 96.7 2.1069 5.0 384.0 20.9 394.05 16.47]\n",
      "0.742522041858\n",
      "[-0.40349384 -0.48832004 -0.37538041 -0.27288841 -0.29910567 -0.6179684\n",
      "  1.000203   -0.80320985 -0.52493098 -0.14549091  1.13299322  0.41034991\n",
      "  0.53341842]\n",
      "[-0.40349384 -0.48832004 -0.37538041 -0.27288841 -0.29910567 -0.6179684\n",
      "  1.000203   -0.80320985 -0.52493098 -0.14549091  1.13299322  0.41034991\n",
      "  0.53341842]\n",
      "score =     0.742522\n",
      "Hold out the following range: 303-404\n",
      "[-- -- -- -- -- -- -- -- -- -- -- -- --]\n",
      "[0.13262 0.0 8.56 0.0 0.52 5.851 96.7 2.1069 5.0 384.0 20.9 394.05 16.47]\n",
      "0.742522041858\n",
      "[-0.40349384 -0.48832004 -0.37538041 -0.27288841 -0.29910567 -0.6179684\n",
      "  1.000203   -0.80320985 -0.52493098 -0.14549091  1.13299322  0.41034991\n",
      "  0.53341842]\n",
      "[-0.40349384 -0.48832004 -0.37538041 -0.27288841 -0.29910567 -0.6179684\n",
      "  1.000203   -0.80320985 -0.52493098 -0.14549091  1.13299322  0.41034991\n",
      "  0.53341842]\n",
      "score =     0.742522\n",
      "Hold out the following range: 404-505\n",
      "[-- -- -- -- -- -- -- -- -- -- -- -- --]\n",
      "[0.13262 0.0 8.56 0.0 0.52 5.851 96.7 2.1069 5.0 384.0 20.9 394.05 16.47]\n",
      "0.742522041858\n",
      "[-0.40349384 -0.48832004 -0.37538041 -0.27288841 -0.29910567 -0.6179684\n",
      "  1.000203   -0.80320985 -0.52493098 -0.14549091  1.13299322  0.41034991\n",
      "  0.53341842]\n",
      "[-0.40349384 -0.48832004 -0.37538041 -0.27288841 -0.29910567 -0.6179684\n",
      "  1.000203   -0.80320985 -0.52493098 -0.14549091  1.13299322  0.41034991\n",
      "  0.53341842]\n",
      "score =     0.742522\n",
      "[0.7425220418579892, 0.7425220418579892, 0.7425220418579892, 0.7425220418579892, 0.7425220418579892]\n"
     ]
    }
   ],
   "source": [
    "# TODO: problem with masking arrays\n",
    "\n",
    "X = boston.data[:505]  # we make it divisible by n_folds to make the code simpler\n",
    "y = boston.target[:505]\n",
    "scores = []\n",
    "n_folds = 5\n",
    "n_samples = len(X)\n",
    "fold_size = n_samples / n_folds\n",
    "alpha = 1.0\n",
    "\n",
    "for fold in range(n_folds):\n",
    "    \n",
    "    X_hold_out_mask = np.zeros(X.shape, dtype=np.bool)\n",
    "    y_hold_out_mask = np.zeros(y.shape, dtype=np.bool)\n",
    "    \n",
    "    # assign True to the samples that are supposed to be held out in this fold\n",
    "    b = int((fold)*fold_size)\n",
    "    e = int((fold+1)*fold_size)\n",
    "    print(\"Hold out the following range: {0}-{1}\".format(b,e))\n",
    "    X_hold_out_mask[b:e,:] = True\n",
    "    y_hold_out_mask[b:e] = True\n",
    "    X_training_mask = ~X_hold_out_mask  # training data is inverse of hold out data\n",
    "    y_training_mask = ~y_hold_out_mask\n",
    "\n",
    "    # assign training and hold-out portions\n",
    "    X_train = np.ma.masked_array(X, X_hold_out_mask)\n",
    "    y_train = np.ma.masked_array(y, y_hold_out_mask)\n",
    "    X_test = np.ma.masked_array(X, X_training_mask)\n",
    "    y_test = np.ma.masked_array(y, y_training_mask)\n",
    "    \n",
    "    # FIXME - masking works here\n",
    "    print(X_test[105,:])\n",
    "    print(X_train[105,:])\n",
    "\n",
    "    # build model - scaling doesn't seem to be using masks!!\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(X_train)\n",
    "    X_train = scaler.transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "\n",
    "    ridge = Ridge(alpha)\n",
    "    ridge.fit(X_train, y_train)\n",
    "    print(ridge.score(X_train, y_train))\n",
    "\n",
    "    # FIXME - but masking is now gone!\n",
    "    print(X_test[105,:])\n",
    "    print(X_train[105,:])\n",
    "\n",
    "    # compute scores\n",
    "    score = ridge.score(X_test, y_test)\n",
    "    print(\"score = {:12.6f}\".format(score))\n",
    "    scores.append(score)\n",
    "    \n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3\n",
    "Compare the result of your implementation with the result of the ``cross_val_score`` method in scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.6386759   0.72005835  0.58512144  0.09886789 -0.174504  ]\n"
     ]
    }
   ],
   "source": [
    "X_train = X\n",
    "y_train = y\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "ridge = Ridge(1.0)\n",
    "ridge.fit(X_train, y_train)\n",
    "scores_sklearn = cross_val_score(ridge,X_train,y_train,cv=5)\n",
    "\n",
    "# compare scores_sklearn with scores\n",
    "print(scores_sklearn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter selection with cross-validation\n",
    "### Task 4\n",
    "Implement the same search over the parameter ``alpha`` in ``Ridge`` that you did in Task 1, but instead of splitting the data three times use cross-validation.\n",
    "In more detail:\n",
    "- Split the Boston housing data (with polynomial features) into two parts, training and testing\n",
    "- Loop over different values of alpha\n",
    "- for each value of alpha, call ``cross_val_score`` on the training set, and compute the mean cross-validated accuracy.\n",
    "- Select the parameter with the best mean crossvalidation accuracy, and build a model on all of the training data\n",
    "- evaluate the model on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing parameter search...\n",
      "alpha: 0.001\n",
      "Cross validated scores:\n",
      "[ 0.76238697  0.56939068  0.77952221  0.70772969  0.79034167]\n",
      "Mean cv score:     0.721874\n",
      "\n",
      "alpha: 0.01\n",
      "Cross validated scores:\n",
      "[ 0.76240138  0.56938802  0.77952438  0.7077228   0.79035472]\n",
      "Mean cv score:     0.721878\n",
      "\n",
      "alpha: 0.1\n",
      "Cross validated scores:\n",
      "[ 0.76254486  0.56936155  0.77954572  0.70765383  0.79048404]\n",
      "Mean cv score:     0.721918\n",
      "\n",
      "alpha: 1.0\n",
      "Cross validated scores:\n",
      "[ 0.76392265  0.5691061   0.77972178  0.70696038  0.79166431]\n",
      "Mean cv score:     0.722275\n",
      "\n",
      "alpha: 10.0\n",
      "Cross validated scores:\n",
      "[ 0.77374246  0.56785091  0.77921536  0.70018795  0.79683623]\n",
      "Mean cv score:     0.723567\n",
      "\n",
      "alpha: 100.0\n",
      "Cross validated scores:\n",
      "[ 0.78133063  0.59449826  0.74215667  0.65395722  0.76706821]\n",
      "Mean cv score:     0.707802\n",
      "\n",
      "alpha: 1000.0\n",
      "Cross validated scores:\n",
      "[ 0.57349832  0.53316797  0.48419302  0.42576949  0.52893181]\n",
      "Mean cv score:     0.509112\n",
      "\n",
      "best mean cross-validation score: 0.724\n",
      "best alpha  = 10.000\n",
      "Performing fit on entire training set...\n",
      "Peforming test...\n",
      "test-set score: 0.633709\n"
     ]
    }
   ],
   "source": [
    "alphas = np.logspace(-3, 3, 7)\n",
    "X_train, X_test, y_train, y_test = train_test_split(boston.data, boston.target, random_state=0)\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "print(\"Performing parameter search...\")\n",
    "scores = []\n",
    "for a in alphas:\n",
    "    print(\"alpha: {0}\".format(a))\n",
    "    ridge = Ridge(a)\n",
    "    ridge.fit(X_train, y_train)\n",
    "    cvscore = cross_val_score(ridge,X_train,y_train,cv=5)\n",
    "    print(\"Cross validated scores:\")\n",
    "    print(cvscore)\n",
    "    score = np.mean(cvscore)\n",
    "    scores.append(score)\n",
    "    print(\"Mean cv score: {0:12.6f}\\n\".format(score))\n",
    "    \n",
    "print(\"best mean cross-validation score: {:.3f}\".format(scores[np.argmax(scores)]))\n",
    "myalpha = alphas[np.argmax(scores)]\n",
    "print(\"best alpha  = {:.3f}\".format(myalpha))\n",
    "\n",
    "print(\"Performing fit on entire training set...\")\n",
    "ridge = Ridge(myalpha)\n",
    "ridge.fit(X_trainval, y_trainval)\n",
    "print(\"Peforming test...\")\n",
    "score = ridge.score(X_test, y_test)\n",
    "print(\"test-set score: {:3f}\".format(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GridSearchCV\n",
    "Because searching for the parameters of a model is such a common task, scikit-learn provides ``GridSearchCV`` which implements the procedure from Task 4 (with some bells an whistles).\n",
    "To use ``GridSearchCV`` we simply have to define a parameter grid to search as a dictionary, with the key the name of the parameter, and the values the parameters we like to try. The ``GridSearchCV`` class has the same interface as the classification and regression models, and we can call ``fit`` to perform the grid-search with cross-validation. It even refits the model using the best parameters! We can then use ``predict`` or ``score`` to use the model with the best parameters, retrained on the whole training data.\n",
    "\n",
    "### Task 5\n",
    "Do the same search from Task 4 (and Task 1) again, this time using ``GridSearchCV`` (from the ``sklearn.model_selection`` module)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best mean cross-validation score: 0.718\n",
      "best parameters: {'alpha': 10.0}\n",
      "test-set score: 0.627\n"
     ]
    }
   ],
   "source": [
    "alphas = np.logspace(-3, 3, 7)\n",
    "param_grid = {'alpha':  alphas}\n",
    "grid = GridSearchCV(Ridge(), param_grid=param_grid, cv=10, return_train_score=True)\n",
    "grid.fit(X_train, y_train)\n",
    "print(\"best mean cross-validation score: {:.3f}\".format(grid.best_score_))\n",
    "print(\"best parameters: {}\".format(grid.best_params_))\n",
    "print(\"test-set score: {:.3f}\".format(grid.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ``GridSearchCV`` object stored a lot of useful information from the grid-search in the ``cv_results_`` attribute.\n",
    "The easiest way to access it is to convert it to a pandas datafram:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(grid.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['mean_fit_time', 'mean_score_time', 'mean_test_score',\n",
       "       'mean_train_score', 'param_alpha', 'params', 'rank_test_score',\n",
       "       'split0_test_score', 'split0_train_score', 'split1_test_score',\n",
       "       'split1_train_score', 'split2_test_score', 'split2_train_score',\n",
       "       'split3_test_score', 'split3_train_score', 'split4_test_score',\n",
       "       'split4_train_score', 'split5_test_score', 'split5_train_score',\n",
       "       'split6_test_score', 'split6_train_score', 'split7_test_score',\n",
       "       'split7_train_score', 'split8_test_score', 'split8_train_score',\n",
       "       'split9_test_score', 'split9_train_score', 'std_fit_time',\n",
       "       'std_score_time', 'std_test_score', 'std_train_score'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     {'alpha': 0.001}\n",
       "1      {'alpha': 0.01}\n",
       "2       {'alpha': 0.1}\n",
       "3       {'alpha': 1.0}\n",
       "4      {'alpha': 10.0}\n",
       "5     {'alpha': 100.0}\n",
       "6    {'alpha': 1000.0}\n",
       "Name: params, dtype: object"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can even plot the cross-validation accuracies and their associated uncertainties:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'param_n_neighbors'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-cc5f4d331cbc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'param_alpha'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'mean_train_score'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'param_alpha'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'mean_test_score'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgca\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m plt.fill_between(results.param_n_neighbors.astype(np.int),\n\u001b[0m\u001b[1;32m      4\u001b[0m                  \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mean_train_score'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'std_train_score'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                  results['mean_train_score'] - results['std_train_score'], alpha=0.2)\n",
      "\u001b[0;32m/usr/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   3612\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3613\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3614\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3615\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3616\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'param_n_neighbors'"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f5d244077b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results.plot('param_alpha', 'mean_train_score')\n",
    "results.plot('param_alpha', 'mean_test_score', ax=plt.gca())\n",
    "plt.fill_between(results.param_.astype(np.int),\n",
    "                 results['mean_train_score'] + results['std_train_score'],\n",
    "                 results['mean_train_score'] - results['std_train_score'], alpha=0.2)\n",
    "plt.fill_between(results.param_n_neighbors.astype(np.int),\n",
    "                 results['mean_test_score'] + results['std_test_score'],\n",
    "                 results['mean_test_score'] - results['std_test_score'], alpha=0.2)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 6\n",
    "Select the best value of ``n_neighbors`` for using ``KNeighborsClassifier`` on the ``digits`` dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation Metrics and scoring\n",
    "\n",
    "In this section, we'll look at different evaluation metrics in scikit-learn and how to use them.\n",
    "There's two main ways to use metrics:\n",
    "- As functions in the ``sklearn.metrics`` module, such as ``accuracy_score`` and ``roc_auc``. These take the true labels and the predictions as arguments.\n",
    "- By specifying a metrics in ``cross_val_score``, ``GridSearchCV`` or another evaluation method using the ``scoring`` keyword, i.e. ``cross_val_score(..., scoring='roc_auc')``."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics for binary classification\n",
    "As we mentioned, accuracy is not a great metric in imbalanced classification problems.\n",
    "We'll look at some alternatives.\n",
    "\n",
    "### Task 7\n",
    "Create an imbalanced classification problem from the digits dataset by classifying the digit 4 against all other digits.\n",
    "Split the data into training and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ....\n",
    "# create X_train, X_test, y_train, y_test for \"4 vs rest\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now train a ``LogisticRegression`` model, a ``DummyClassifier(strategy='most_frequent')`` and a ``DecisionTreeClassifier(max_depth=2)``, and compare their test-set accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "lr = LogisticRegression()\n",
    "tree = DecisionTreeClassifier(max_depth=2)\n",
    "dummy = DummyClassifier(strategy='most_frequent')\n",
    "\n",
    "# build models\n",
    "# compare them using accuracy (for example using .score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get a better picture, now use the ``classification_report`` function from ``sklearn.metrics``:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The classification report provides precision and recall for the default threshold. To look at all possible thresholds, we can plot the precision-recall curve:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_probs_lr = lr.predict_proba(X_test)[:, 1]\n",
    "# complete:\n",
    "# positive_probs_tree = tree.\n",
    "# plot curves for tree and logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can look at a summary by computing the average precision (``average_precision_score``):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, to use something like ``average_precision_score`` in cross-validation, we can simply specify the ``scoring`` argument of ``cross_val_score``. Use ``cross_val_score`` to compute the 5 fold cross-validated average precision of ``LogisticRegression`` and ``DecisionTreeClassifier(max_depth=2)``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ... solution here..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
