{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The idea of this project it to get familiar with convolutional neural networks and solve the \"cats vs dogs\" captcha challenge, which tries to automatically classify images as cats or dogs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Started\n",
    "To get started with Convnets, read up on the concepts in the [Deep Learning Book, Chapters 9.1-9.3](http://www.deeplearningbook.org/contents/convnets.html).\n",
    "The Stanford course on neural networks also has a [great explanation](http://cs231n.github.io/convolutional-networks/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding Convolutions\n",
    "Before diving into convolutional neural nets, it's a good idea to understand how convolutions work. A convolution is simply a filter (as in signal processing) applied to all positions of a signal. Very simple filters are those that smooth or blurr, and those that compute derivatives.\n",
    "\n",
    "### 1d convolutions\n",
    "Let's start with smoothing a 1d signal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a noisy signal\n",
    "import numpy as np\n",
    "# use a fixed seed for simplicity\n",
    "rng = np.random.RandomState(0)\n",
    "noise = rng.normal(size=(200,))\n",
    "random_walk = np.cumsum(noise)\n",
    "print(random_walk[: 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.plot(random_walk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convolutions in n dimensions are implemented in ``scipy.ndimage.convolve``. Let's start with smoothing our signal. Use ``convolve`` to convolve the signale with a constant filter (``np.ones()``). Start with length 3, and then try different length. Visualize the result of the convolution together with the original signal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.ndimage import convolve\n",
    "# solution here ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's try a slightly more complicated filter: a Gaussian filter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gaussian_filter = np.exp(-np.linspace(-2, 2, 15) ** 2)\n",
    "gaussian_filter /= gaussian_filter.sum()\n",
    "plt.plot(gaussian_filter)\n",
    "gaussian_filter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convolve the signal with the Gaussian filter and compare the results to the constant filter. What does changing the radius or size of the filter do?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A somewhat more interesting filter is the derivative. There's many ways to encode a derivative, the simplest is the filter ``[-1, 1]``. Use this filter on the signal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# solution .."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes a better way to compute the derivative is to smooth first. Convolutions are associative, meaning applying one filter and then another is the same as first convolving the two filters, then applying the result.\n",
    "\n",
    "Apply the ``[-1, 1]`` filter to the ``gaussian_filter`` above and visualize the result. Then, convolve the original signal with this smoothed derivative filter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2d convolutions\n",
    "Next, we'll apply the same principles to a 2d signal.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.misc import imread\n",
    "image = imread(\"thisisdog.png\")\n",
    "plt.imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for simplicity, convert to grayscale for now:\n",
    "gray = image.mean(axis=2)\n",
    "plt.imshow(gray, cmap=plt.cm.Greys_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a 2d Gaussian filter from the 1d Gaussian filter above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gaussian_2d = gaussian_filter * gaussian_filter[:, np.newaxis]\n",
    "plt.matshow(gaussian_2d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now smooth the image with the 2d Gaussian filter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Computing gradients in an image is the same as doing \"edge detection\". Convolve the 2d Gaussian with the ``[-1, 1]`` filter to get an edge detection filter. Then run the filter on the image. Create filters for both horizontal and vertical edge detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A baseline network on MNIST\n",
    "For many years, the MNIST dataset of handwritten digits (much larger than the ``digits`` dataset we were using) was a standard benchmark.\n",
    "Start by applying a standard Multilayer perceptron (no convolutions) to the MNIST dataset as a baseline.\n",
    "If you get stuck, you can consult the example [here](https://github.com/keras-team/keras/blob/master/examples/mnist_mlp.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "\n",
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 20\n",
    "\n",
    "# the data, shuffled and split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "x_train = x_train.reshape(60000, 784)\n",
    "x_test = x_test.reshape(10000, 784)\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "# build sequential model as yesterday"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional neural networks with Keras\n",
    "\n",
    "Now compare this to a convolutional neural network with keras.\n",
    "Again you can use the ``Sequential`` model, but this time we are using the Conv2D layers and MaxPooling2D layers (see keras docs).\n",
    "If you get stuck, you can look at [this example](https://github.com/keras-team/keras/blob/master/examples/mnist_cnn.py)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "\n",
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 12\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 28, 28\n",
    "\n",
    "# the data, shuffled and split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The cats and dogs dataset.\n",
    "\n",
    "You could try to learn a network like this on the cats and dogs dataset.\n",
    "However, there is unlikely to be enough data in the dataset. Instead, we will use a neural network that was trained on the much larger \"imagenet\" dataset.\n",
    "\n",
    "Start by downloading the cats and dogs data here:\n",
    "\n",
    "https://www.kaggle.com/c/dogs-vs-cats/data\n",
    "\n",
    "or if you don't have a kaggle account here:\n",
    "\n",
    "https://www.microsoft.com/en-us/download/confirmation.aspx?id=54765\n",
    "\n",
    "Then load one of the models shipped with keras, start with VGG 16:\n",
    "https://keras.io/applications/#vgg16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data similar to MNIST above\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "X_pre = preprocess_input(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the vgg net to extract features:\n",
    "features = model.predict(X_pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now train a scikit-learn model, like logistic regression, to distinguish cats and dogs based on these features."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
